{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca19aed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\victor\\miniconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: torch in c:\\users\\victor\\miniconda3\\lib\\site-packages (1.13.0+cu117)\n",
      "Requirement already satisfied: datasets in c:\\users\\victor\\miniconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\victor\\miniconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\victor\\miniconda3\\lib\\site-packages (0.0.post1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (0.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\victor\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\victor\\miniconda3\\lib\\site-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\victor\\miniconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.7 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\victor\\miniconda3\\lib\\site-packages (from datasets) (1.5.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from datasets) (10.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\victor\\miniconda3\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3399d885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.24\n",
      "  Downloading scikit_learn-0.24.0-cp38-cp38-win_amd64.whl (6.9 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.9.3-cp38-cp38-win_amd64.whl (39.8 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\victor\\miniconda3\\lib\\site-packages (from scikit-learn==0.24) (1.23.4)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-0.24.0 scipy-1.9.3 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4911041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c23e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Local\\Temp\\ipykernel_10588\\4285109436.py:1: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('labeled_reviews.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('labeled_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9de35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c5e879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>isSuggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>better than any you can get at a restaurant!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I cut back on the mayo, and made up the differ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i think i did something wrong because i could ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>easily the best i have ever had.  juicy flavor...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An excellent dish.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>I doubled the amount of coffee powder in this ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>I love this dish. To me it is a winter comfort...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>We really enjoyed this chicken! I added the or...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Sounds good !</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>This was great!  Good flavor, easy to make and...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review isSuggestion\n",
       "0          better than any you can get at a restaurant!        False\n",
       "1     I cut back on the mayo, and made up the differ...         True\n",
       "2     i think i did something wrong because i could ...        False\n",
       "3     easily the best i have ever had.  juicy flavor...        False\n",
       "4                                    An excellent dish.        False\n",
       "...                                                 ...          ...\n",
       "1003  I doubled the amount of coffee powder in this ...         True\n",
       "1004  I love this dish. To me it is a winter comfort...        False\n",
       "1005  We really enjoyed this chicken! I added the or...         True\n",
       "1006                                      Sounds good !        False\n",
       "1007  This was great!  Good flavor, easy to make and...         True\n",
       "\n",
       "[1008 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df[['Review', 'isSuggestion']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "852cde34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'tasty. you can substitute granulated sugar for the palm sugar.', 'label': True}\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df).train_test_split(test_size=0.2)\n",
    "dataset = dataset.remove_columns([\"__index_level_0__\"])\n",
    "dataset = dataset.rename_column(\"Review\", \"text\")\n",
    "dataset = dataset.rename_column(\"isSuggestion\", \"label\")\n",
    "print(dataset['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee47e3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca25891684c427e8d9a3f54746059e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b3ddc76e8c4930ad826d22afb618b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "#tokenized_datasets['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b04027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## CPU training\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    print(logits, labels)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3d47b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## GPU training\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2).to(\"cuda\")\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\"./test_model\").to(\"cuda\")\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    print(logits, labels)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=4, gradient_accumulation_steps=4,\n",
    "                                  num_train_epochs=5, output_dir=\"trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cdc7e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\Victor\\miniconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 806\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 250\n",
      "  Number of trainable parameters = 108311810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:55, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.381801</td>\n",
       "      <td>0.846535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.363781</td>\n",
       "      <td>0.851485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.483966</td>\n",
       "      <td>0.866337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663138</td>\n",
       "      <td>0.866337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.634039</td>\n",
       "      <td>0.876238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1237105   1.4541268 ]\n",
      " [-1.0190567   1.2225975 ]\n",
      " [-0.71004295  0.86320883]\n",
      " [ 0.9851582  -1.414731  ]\n",
      " [ 0.455781   -0.51667595]\n",
      " [ 1.5259453  -1.992947  ]\n",
      " [-0.56560564  0.9540572 ]\n",
      " [ 1.5718825  -1.9528058 ]\n",
      " [-1.0523838   1.4380155 ]\n",
      " [ 1.5324883  -1.9126877 ]\n",
      " [-0.9930875   1.202351  ]\n",
      " [-1.1659946   1.446707  ]\n",
      " [ 1.5032706  -1.9590857 ]\n",
      " [ 1.4735982  -1.984615  ]\n",
      " [ 1.6179903  -2.1259592 ]\n",
      " [ 1.4282984  -1.8949379 ]\n",
      " [-1.1716237   1.4492362 ]\n",
      " [-1.0003037   1.3582871 ]\n",
      " [-1.1582823   1.4526454 ]\n",
      " [-1.1542687   1.4452809 ]\n",
      " [ 1.5650826  -2.085507  ]\n",
      " [ 1.4244918  -1.9197546 ]\n",
      " [-1.1300865   1.4867948 ]\n",
      " [ 1.5039482  -2.0335443 ]\n",
      " [-1.101792    1.3937261 ]\n",
      " [ 1.4492002  -1.8351122 ]\n",
      " [-1.0568866   1.3034099 ]\n",
      " [ 1.4677248  -1.8842996 ]\n",
      " [ 1.517832   -1.982825  ]\n",
      " [-0.8785474   1.0219867 ]\n",
      " [ 1.5611639  -1.9763621 ]\n",
      " [-0.9093592   1.1980397 ]\n",
      " [ 1.4967957  -1.9888787 ]\n",
      " [ 1.5506704  -2.0249147 ]\n",
      " [-0.76973826  1.1444755 ]\n",
      " [ 0.29262325 -0.18039347]\n",
      " [ 1.5661187  -2.1327095 ]\n",
      " [ 1.420981   -1.8715757 ]\n",
      " [-1.1716915   1.4228367 ]\n",
      " [-1.1814588   1.4877855 ]\n",
      " [ 1.3839357  -1.8495071 ]\n",
      " [-0.9716336   1.1733727 ]\n",
      " [ 1.4951957  -2.010846  ]\n",
      " [ 1.24319    -1.6299058 ]\n",
      " [ 1.5519884  -2.0212545 ]\n",
      " [ 1.4232547  -1.8988869 ]\n",
      " [ 1.4691705  -1.8982161 ]\n",
      " [ 1.0682931  -1.4636325 ]\n",
      " [-1.1538168   1.4904099 ]\n",
      " [ 0.00353484  0.22742395]\n",
      " [ 1.5371197  -1.9975747 ]\n",
      " [ 0.05229394  0.10330169]\n",
      " [-1.0915972   1.3499346 ]\n",
      " [-1.1611367   1.4260241 ]\n",
      " [ 1.3390864  -1.8037317 ]\n",
      " [-1.1513642   1.4378608 ]\n",
      " [ 1.5145404  -1.9581485 ]\n",
      " [-1.1651479   1.4152194 ]\n",
      " [ 1.0983527  -1.6038127 ]\n",
      " [ 1.5656496  -2.1017034 ]\n",
      " [ 0.89304096 -1.1336447 ]\n",
      " [ 1.5209932  -1.9240991 ]\n",
      " [ 1.2846293  -1.766597  ]\n",
      " [ 1.517417   -1.995362  ]\n",
      " [-1.1384873   1.5049134 ]\n",
      " [ 1.1562804  -1.4274782 ]\n",
      " [ 1.6008835  -2.08206   ]\n",
      " [ 1.3816468  -1.8858277 ]\n",
      " [ 1.4121273  -1.9113462 ]\n",
      " [-0.9907266   1.2034549 ]\n",
      " [ 1.5536588  -2.06999   ]\n",
      " [ 1.5818512  -2.071727  ]\n",
      " [ 1.2454976  -1.6733692 ]\n",
      " [ 1.6253396  -2.0316844 ]\n",
      " [ 0.54036015 -0.76670516]\n",
      " [ 0.02475701  0.1315959 ]\n",
      " [ 1.4840261  -1.9340631 ]\n",
      " [-1.0973754   1.470389  ]\n",
      " [ 0.9496155  -1.2978815 ]\n",
      " [-1.1003623   1.368895  ]\n",
      " [-0.6270398   0.8963935 ]\n",
      " [ 1.1085559  -1.4675822 ]\n",
      " [ 1.5289488  -1.9816351 ]\n",
      " [ 1.622601   -2.0878117 ]\n",
      " [ 1.534184   -2.0084572 ]\n",
      " [-1.063084    1.4165264 ]\n",
      " [ 1.4538018  -1.8959476 ]\n",
      " [-0.76721895  1.07097   ]\n",
      " [ 0.6400831  -0.75604624]\n",
      " [ 1.5570371  -2.1331325 ]\n",
      " [-1.1881146   1.4719969 ]\n",
      " [ 1.1542481  -1.585885  ]\n",
      " [ 1.5677086  -2.0912812 ]\n",
      " [ 1.314839   -1.7094779 ]\n",
      " [ 1.5752436  -2.0769835 ]\n",
      " [ 1.5152776  -2.0701013 ]\n",
      " [-1.0403893   1.2660837 ]\n",
      " [ 1.5158074  -2.0017905 ]\n",
      " [-0.81352264  1.1489979 ]\n",
      " [ 1.0842364  -1.4771783 ]\n",
      " [ 0.7992922  -1.0822638 ]\n",
      " [ 1.2795867  -1.5129867 ]\n",
      " [ 1.4996214  -2.0224302 ]\n",
      " [ 1.1698337  -1.5905731 ]\n",
      " [ 1.0061125  -1.4107056 ]\n",
      " [-1.1271359   1.3866317 ]\n",
      " [ 0.94162226 -1.1454006 ]\n",
      " [ 1.4133447  -1.8384217 ]\n",
      " [-1.0816897   1.3117938 ]\n",
      " [-0.58755505  0.80751455]\n",
      " [-1.1573373   1.3933702 ]\n",
      " [ 1.5685786  -1.9853767 ]\n",
      " [-1.1662892   1.4237467 ]\n",
      " [-1.1105943   1.3990226 ]\n",
      " [-0.95123744  1.2868496 ]\n",
      " [-0.94572836  1.3515713 ]\n",
      " [-0.86563593  1.1368653 ]\n",
      " [ 1.6406099  -2.0891654 ]\n",
      " [ 1.5247618  -2.1140962 ]\n",
      " [-1.2192334   1.5003089 ]\n",
      " [ 1.2256248  -1.65479   ]\n",
      " [-1.1555821   1.4329859 ]\n",
      " [-0.22311477  0.5855079 ]\n",
      " [ 1.330102   -1.76056   ]\n",
      " [ 0.6191087  -0.64252335]\n",
      " [-1.1538606   1.4447197 ]\n",
      " [ 1.1980786  -1.7217964 ]\n",
      " [-0.9060562   1.2081878 ]\n",
      " [ 1.4637523  -1.9703934 ]\n",
      " [-1.0433902   1.3456419 ]\n",
      " [ 1.5689266  -2.1810052 ]\n",
      " [ 1.5488256  -2.1045625 ]\n",
      " [-1.2072517   1.5216714 ]\n",
      " [-0.85758245  1.2169203 ]\n",
      " [-0.6752024   1.093318  ]\n",
      " [ 1.6030598  -2.069074  ]\n",
      " [-1.2247609   1.5066615 ]\n",
      " [ 1.1777692  -1.6385633 ]\n",
      " [-1.0799053   1.2751834 ]\n",
      " [-1.0859883   1.43855   ]\n",
      " [ 1.4767324  -2.073215  ]\n",
      " [-0.4079726   0.72071314]\n",
      " [-0.52531666  0.69099396]\n",
      " [ 1.5448502  -2.102174  ]\n",
      " [ 1.5568007  -2.0637362 ]\n",
      " [ 1.503277   -2.047173  ]\n",
      " [ 1.5714549  -2.0431068 ]\n",
      " [ 1.4554107  -1.8839926 ]\n",
      " [-1.087494    1.4529687 ]\n",
      " [ 1.385026   -1.8656964 ]\n",
      " [ 1.5146561  -1.9988906 ]\n",
      " [ 0.04316518  0.19276851]\n",
      " [-0.06453773  0.25174987]\n",
      " [ 1.5818722  -2.0389152 ]\n",
      " [-1.1686155   1.4666758 ]\n",
      " [ 1.481822   -1.9358249 ]\n",
      " [ 1.5388672  -1.9955353 ]\n",
      " [ 1.4794867  -1.8825396 ]\n",
      " [ 1.1102226  -1.5446206 ]\n",
      " [-1.1576651   1.4622489 ]\n",
      " [-1.1263325   1.3363296 ]\n",
      " [-1.1819309   1.4954698 ]\n",
      " [ 1.3271037  -1.9433885 ]\n",
      " [-1.0685661   1.376077  ]\n",
      " [ 1.3700284  -1.8393115 ]\n",
      " [ 1.2933915  -1.6531727 ]\n",
      " [ 1.482388   -2.0762844 ]\n",
      " [ 1.0675646  -1.5126275 ]\n",
      " [-0.8569785   1.1822019 ]\n",
      " [-0.43586096  0.6478245 ]\n",
      " [ 1.3294612  -1.7331163 ]\n",
      " [-1.0605317   1.4116615 ]\n",
      " [-1.0710111   1.2442384 ]\n",
      " [ 1.5699296  -2.097094  ]\n",
      " [ 1.4665385  -1.9165083 ]\n",
      " [ 1.4089367  -1.9620829 ]\n",
      " [-1.0945098   1.4005365 ]\n",
      " [ 1.5245088  -1.9639596 ]\n",
      " [-0.89320356  1.3662978 ]\n",
      " [ 1.4645804  -1.9599046 ]\n",
      " [-0.90824103  1.148907  ]\n",
      " [ 1.5507956  -2.0270362 ]\n",
      " [-0.70127857  0.8586547 ]\n",
      " [ 1.5877745  -2.0202565 ]\n",
      " [ 1.2973822  -1.7940212 ]\n",
      " [-0.82779545  1.0120643 ]\n",
      " [ 1.4868526  -1.9181654 ]\n",
      " [ 1.4860605  -2.024999  ]\n",
      " [-1.1506797   1.5028665 ]\n",
      " [ 1.5219623  -2.0495827 ]\n",
      " [ 1.3677185  -1.7569389 ]\n",
      " [ 1.5041683  -1.9192098 ]\n",
      " [-0.966193    1.2732536 ]\n",
      " [-0.7828283   0.96990156]\n",
      " [ 1.4768713  -1.920582  ]\n",
      " [-1.1767749   1.4438859 ]\n",
      " [-1.1330528   1.3975142 ]\n",
      " [ 1.3436528  -1.7168325 ]\n",
      " [ 1.4987378  -1.925196  ]\n",
      " [ 1.5975312  -2.0052097 ]\n",
      " [ 0.5083354  -0.34405848]\n",
      " [ 1.594645   -2.1008112 ]] [1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96265316  1.4542469 ]\n",
      " [ 0.7782103  -1.1815515 ]\n",
      " [ 1.0568236  -1.4304788 ]\n",
      " [ 1.4408233  -2.2374926 ]\n",
      " [ 0.8810923  -1.3036765 ]\n",
      " [ 1.5558051  -2.2292738 ]\n",
      " [ 1.3629775  -2.1654572 ]\n",
      " [ 1.7369934  -2.4506698 ]\n",
      " [-0.92688394  1.0796431 ]\n",
      " [ 1.5914642  -2.1877935 ]\n",
      " [-1.163704    1.5248274 ]\n",
      " [-1.1211185   1.5652767 ]\n",
      " [ 1.470286   -2.092972  ]\n",
      " [ 1.3643813  -2.0680745 ]\n",
      " [ 1.6598356  -2.4233294 ]\n",
      " [ 1.59527    -2.327755  ]\n",
      " [ 0.27905616 -0.39595532]\n",
      " [-0.87283206  1.0013694 ]\n",
      " [-1.2052292   1.5716692 ]\n",
      " [-1.074748    1.458307  ]\n",
      " [ 1.585724   -2.4036956 ]\n",
      " [ 1.4465524  -2.1209533 ]\n",
      " [-1.0041587   1.179615  ]\n",
      " [ 1.6727937  -2.4429765 ]\n",
      " [-0.2937753   0.43567985]\n",
      " [ 1.844057   -2.4219267 ]\n",
      " [ 0.3573003  -0.446126  ]\n",
      " [ 1.4894145  -2.1666117 ]\n",
      " [ 1.514642   -2.231553  ]\n",
      " [ 0.6362531  -0.95024794]\n",
      " [ 1.5656282  -2.2311022 ]\n",
      " [ 0.61835355 -0.8985198 ]\n",
      " [ 1.5002853  -2.244858  ]\n",
      " [ 1.6393437  -2.4126656 ]\n",
      " [ 0.7431615  -1.0519656 ]\n",
      " [ 1.4147532  -2.0632625 ]\n",
      " [ 1.6241975  -2.4067922 ]\n",
      " [ 1.741888   -2.4562726 ]\n",
      " [ 0.5645716  -0.92521924]\n",
      " [-1.140935    1.5856423 ]\n",
      " [ 1.5149937  -2.1073527 ]\n",
      " [ 0.56035435 -0.7975586 ]\n",
      " [ 1.5758747  -2.1991925 ]\n",
      " [ 1.6104072  -2.2507017 ]\n",
      " [ 1.4464068  -2.235408  ]\n",
      " [ 1.5267342  -2.1724749 ]\n",
      " [ 1.2528766  -1.8522142 ]\n",
      " [ 1.6276294  -2.4282722 ]\n",
      " [-1.3428267   1.6612537 ]\n",
      " [ 0.8804418  -1.2282575 ]\n",
      " [ 1.4529822  -1.9968029 ]\n",
      " [ 1.3191339  -1.9685545 ]\n",
      " [-0.812146    0.9144091 ]\n",
      " [-0.05724714  0.10657037]\n",
      " [ 1.6281983  -2.4061708 ]\n",
      " [-1.1395566   1.5974649 ]\n",
      " [ 1.8589363  -2.5350897 ]\n",
      " [-1.1258899   1.5707284 ]\n",
      " [ 1.3040516  -2.0520072 ]\n",
      " [ 1.7275618  -2.5380526 ]\n",
      " [ 1.3177288  -1.8855958 ]\n",
      " [ 1.9286274  -2.6058893 ]\n",
      " [ 1.7315063  -2.4355679 ]\n",
      " [ 1.5159405  -2.176126  ]\n",
      " [-1.079862    1.5044988 ]\n",
      " [ 1.3540947  -1.7358962 ]\n",
      " [ 1.6279993  -2.2989697 ]\n",
      " [ 1.3595079  -2.166988  ]\n",
      " [ 1.6927774  -2.5307906 ]\n",
      " [ 0.61167353 -0.9020566 ]\n",
      " [ 1.6596615  -2.3784366 ]\n",
      " [ 1.7113432  -2.5464582 ]\n",
      " [ 1.9250118  -2.613635  ]\n",
      " [ 1.5922896  -2.2796628 ]\n",
      " [-0.45999715  0.56984526]\n",
      " [ 1.3162179  -2.0261786 ]\n",
      " [ 1.4471381  -2.1456707 ]\n",
      " [-0.82290304  0.90774524]\n",
      " [ 1.4924873  -2.274375  ]\n",
      " [-0.14893997  0.31688514]\n",
      " [ 0.8255646  -1.0327816 ]\n",
      " [ 1.2652785  -1.7740036 ]\n",
      " [ 1.7448053  -2.387445  ]\n",
      " [ 1.5280951  -2.331065  ]\n",
      " [ 1.7528583  -2.502756  ]\n",
      " [-1.2086895   1.5553011 ]\n",
      " [ 1.3980907  -2.102359  ]\n",
      " [ 0.24139862 -0.27514163]\n",
      " [ 1.2489047  -1.9118668 ]\n",
      " [ 1.7444512  -2.5805495 ]\n",
      " [-1.0594939   1.4820969 ]\n",
      " [ 0.93424004 -1.3164152 ]\n",
      " [ 1.6671294  -2.3910055 ]\n",
      " [ 1.512166   -2.1249244 ]\n",
      " [ 1.4731628  -2.2761    ]\n",
      " [ 1.395102   -2.0679438 ]\n",
      " [-0.42882174  0.41302297]\n",
      " [ 1.7190621  -2.4844356 ]\n",
      " [-0.92444307  1.011922  ]\n",
      " [ 1.5313197  -2.155363  ]\n",
      " [ 1.3043325  -2.093873  ]\n",
      " [ 1.2599066  -1.715714  ]\n",
      " [ 1.6684781  -2.4548414 ]\n",
      " [ 1.0524236  -1.6504258 ]\n",
      " [ 1.4244901  -2.0285623 ]\n",
      " [ 0.8788531  -1.2630666 ]\n",
      " [ 1.2235168  -1.8189131 ]\n",
      " [ 1.9792025  -2.6580906 ]\n",
      " [ 0.6654023  -1.0361748 ]\n",
      " [ 0.01765025  0.18106635]\n",
      " [-1.2803319   1.6188713 ]\n",
      " [ 1.8334631  -2.5217786 ]\n",
      " [-1.242499    1.574079  ]\n",
      " [-1.1132869   1.3371029 ]\n",
      " [-0.7554766   0.82843107]\n",
      " [-0.5692259   0.6817892 ]\n",
      " [ 0.4779399  -0.5977229 ]\n",
      " [ 1.6347798  -2.4951115 ]\n",
      " [ 1.5473922  -2.4657779 ]\n",
      " [-1.216305    1.5764915 ]\n",
      " [ 1.5203631  -2.2739265 ]\n",
      " [-0.0314335   0.08298744]\n",
      " [-0.5255732   0.69242907]\n",
      " [ 1.8650538  -2.633266  ]\n",
      " [ 1.0705973  -1.5823812 ]\n",
      " [-1.0924337   1.430528  ]\n",
      " [ 1.3615108  -2.1525657 ]\n",
      " [-0.1958593   0.24595861]\n",
      " [ 1.8584728  -2.6771839 ]\n",
      " [-0.13388664  0.15327673]\n",
      " [ 1.5950449  -2.4826708 ]\n",
      " [ 1.5990993  -2.4435852 ]\n",
      " [-1.0558177   1.5278304 ]\n",
      " [ 0.5125238  -0.9002549 ]\n",
      " [ 0.52390766 -0.82234246]\n",
      " [ 1.4632483  -2.2081695 ]\n",
      " [-1.1681664   1.5793543 ]\n",
      " [ 1.9017625  -2.5753717 ]\n",
      " [-0.40087372  0.51064605]\n",
      " [ 0.66824746 -0.9656519 ]\n",
      " [ 1.5050677  -2.380801  ]\n",
      " [ 0.05036413  0.08409327]\n",
      " [ 1.1119297  -1.6425227 ]\n",
      " [ 1.5610596  -2.4425347 ]\n",
      " [ 1.6737751  -2.5224545 ]\n",
      " [ 1.516537   -2.354407  ]\n",
      " [ 1.8344485  -2.6679757 ]\n",
      " [ 1.9311527  -2.5695648 ]\n",
      " [-0.9877208   1.4449869 ]\n",
      " [ 1.7291509  -2.4781241 ]\n",
      " [ 1.7584627  -2.531533  ]\n",
      " [ 0.9743868  -1.2212098 ]\n",
      " [ 0.7568996  -1.0265627 ]\n",
      " [ 1.7975035  -2.6500816 ]\n",
      " [-1.2209616   1.5884463 ]\n",
      " [ 0.9845219  -1.4927657 ]\n",
      " [ 1.6706804  -2.4541495 ]\n",
      " [ 1.8396844  -2.607721  ]\n",
      " [ 1.3515357  -2.099658  ]\n",
      " [-1.1174026   1.3462142 ]\n",
      " [-1.1656137   1.3277419 ]\n",
      " [-1.2531497   1.5787394 ]\n",
      " [ 1.3890597  -2.2417943 ]\n",
      " [-1.171073    1.5959908 ]\n",
      " [ 1.6242563  -2.4439452 ]\n",
      " [ 1.3003021  -1.9610432 ]\n",
      " [ 1.3751984  -2.1334562 ]\n",
      " [ 1.2638667  -1.9544995 ]\n",
      " [ 0.5985347  -0.72884995]\n",
      " [ 1.2797511  -2.12229   ]\n",
      " [ 1.2659746  -1.7700132 ]\n",
      " [-1.0494498   1.4743984 ]\n",
      " [ 0.6155781  -1.0459116 ]\n",
      " [ 1.5738436  -2.43565   ]\n",
      " [ 1.8211021  -2.6318414 ]\n",
      " [ 1.5159087  -2.2371085 ]\n",
      " [-1.1547434   1.5870084 ]\n",
      " [ 1.7554373  -2.3741121 ]\n",
      " [-1.3006486   1.5768611 ]\n",
      " [ 1.830602   -2.6158557 ]\n",
      " [-1.034513    1.2610284 ]\n",
      " [ 1.7401108  -2.5067976 ]\n",
      " [ 0.6081011  -1.0046296 ]\n",
      " [ 1.4105012  -2.0693336 ]\n",
      " [ 1.3635622  -2.0315266 ]\n",
      " [ 1.4155315  -2.0909355 ]\n",
      " [ 1.8840967  -2.5655472 ]\n",
      " [ 1.7265944  -2.4719338 ]\n",
      " [-1.0499507   1.4628495 ]\n",
      " [ 1.6327621  -2.4118357 ]\n",
      " [ 1.3973874  -2.048609  ]\n",
      " [ 1.7651871  -2.2834036 ]\n",
      " [-0.97504926  1.1029968 ]\n",
      " [ 1.0505883  -1.3489296 ]\n",
      " [ 1.634795   -2.3670526 ]\n",
      " [-1.3442618   1.5645436 ]\n",
      " [-1.2660826   1.6385669 ]\n",
      " [ 1.4341856  -1.9980001 ]\n",
      " [ 1.815932   -2.4468386 ]\n",
      " [ 1.8665237  -2.5262568 ]\n",
      " [-0.891639    1.3243389 ]\n",
      " [ 1.6385648  -2.402517  ]] [1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.4351783   2.8542237 ]\n",
      " [ 1.1857784  -1.7029889 ]\n",
      " [ 2.246131   -2.9171565 ]\n",
      " [ 2.4231122  -3.2611337 ]\n",
      " [ 2.2026067  -3.0306344 ]\n",
      " [ 2.4397976  -3.1509836 ]\n",
      " [ 2.0718133  -2.8267045 ]\n",
      " [ 2.59217    -3.2455533 ]\n",
      " [-2.359539    2.7631836 ]\n",
      " [ 2.5235953  -3.1269321 ]\n",
      " [-2.3648233   2.7034926 ]\n",
      " [-2.4727352   2.8905053 ]\n",
      " [ 2.538226   -3.2246306 ]\n",
      " [ 2.4585953  -3.239241  ]\n",
      " [ 2.5616407  -3.2129164 ]\n",
      " [ 2.52202    -3.2185593 ]\n",
      " [ 0.3369166  -0.48875615]\n",
      " [-2.33085     2.672593  ]\n",
      " [-2.3910778   2.7660615 ]\n",
      " [-2.2597387   2.655854  ]\n",
      " [ 2.518828   -3.2566745 ]\n",
      " [ 2.4814749  -3.2736573 ]\n",
      " [-1.7473261   2.226534  ]\n",
      " [ 2.4808753  -3.2367358 ]\n",
      " [-1.7662245   2.2008252 ]\n",
      " [ 2.5059588  -3.0596468 ]\n",
      " [ 1.9993559  -2.661753  ]\n",
      " [ 2.4876604  -3.1351402 ]\n",
      " [ 2.5356507  -3.2647977 ]\n",
      " [ 0.19664817 -0.23330586]\n",
      " [ 2.6095967  -3.28896   ]\n",
      " [-0.24809352  0.4987995 ]\n",
      " [ 2.4722018  -3.2114086 ]\n",
      " [ 2.5295691  -3.2846017 ]\n",
      " [-0.63691986  0.90874666]\n",
      " [ 1.5337361  -2.0459936 ]\n",
      " [ 2.507254   -3.212746  ]\n",
      " [ 2.547141   -3.2170506 ]\n",
      " [-0.7194024   1.0034875 ]\n",
      " [-2.4053907   2.8334882 ]\n",
      " [ 2.4144819  -3.237442  ]\n",
      " [ 0.62888175 -0.8631075 ]\n",
      " [ 2.4047985  -3.074882  ]\n",
      " [ 2.340015   -2.9953108 ]\n",
      " [ 2.5062335  -3.2323606 ]\n",
      " [ 2.4382322  -3.1540973 ]\n",
      " [ 2.2147615  -3.0086024 ]\n",
      " [ 2.5659797  -3.257527  ]\n",
      " [-2.288471    2.6480134 ]\n",
      " [ 0.3334877  -0.44582945]\n",
      " [ 2.5088923  -3.159582  ]\n",
      " [ 2.4055974  -3.129561  ]\n",
      " [-1.0205977   1.2607617 ]\n",
      " [-1.4514263   1.8060879 ]\n",
      " [ 2.5930016  -3.3215756 ]\n",
      " [-2.4485586   2.874438  ]\n",
      " [ 2.499155   -3.1481178 ]\n",
      " [-2.3790088   2.7513447 ]\n",
      " [ 2.3470867  -3.134275  ]\n",
      " [ 2.4517376  -3.1765018 ]\n",
      " [ 2.1806002  -2.741829  ]\n",
      " [ 2.519367   -3.1405568 ]\n",
      " [ 2.4906247  -3.1338205 ]\n",
      " [ 2.4617603  -3.1554937 ]\n",
      " [-2.4207017   2.8173432 ]\n",
      " [ 2.3947647  -2.888754  ]\n",
      " [ 2.502015   -3.1750877 ]\n",
      " [ 2.4385982  -3.2362478 ]\n",
      " [ 2.5397005  -3.218486  ]\n",
      " [ 1.689981   -2.1867638 ]\n",
      " [ 2.5583165  -3.2764075 ]\n",
      " [ 2.5060558  -3.2288632 ]\n",
      " [ 2.537226   -3.171152  ]\n",
      " [ 2.5529118  -3.2556794 ]\n",
      " [ 0.58046377 -0.95214313]\n",
      " [ 2.4598565  -3.2255635 ]\n",
      " [ 2.4928398  -3.2311862 ]\n",
      " [-1.3340077   1.7621628 ]\n",
      " [ 2.455394   -3.1717157 ]\n",
      " [-1.8724499   2.1816418 ]\n",
      " [ 0.9833344  -1.2682347 ]\n",
      " [ 2.3673594  -3.0553324 ]\n",
      " [ 2.5345778  -3.2243643 ]\n",
      " [ 2.5507445  -3.2617574 ]\n",
      " [ 2.585332   -3.2867572 ]\n",
      " [-2.393943    2.7944922 ]\n",
      " [ 2.4144104  -3.1043472 ]\n",
      " [ 0.85054123 -1.206272  ]\n",
      " [ 2.0841177  -2.853342  ]\n",
      " [ 2.518804   -3.2804744 ]\n",
      " [-2.3770354   2.7700782 ]\n",
      " [ 2.1680548  -3.0320973 ]\n",
      " [ 2.4804235  -3.1769464 ]\n",
      " [ 2.5688198  -3.2444952 ]\n",
      " [ 2.5305266  -3.2739336 ]\n",
      " [ 2.479597   -3.2435868 ]\n",
      " [-2.2764797   2.5607965 ]\n",
      " [ 2.516516   -3.1872299 ]\n",
      " [-2.2453027   2.6022935 ]\n",
      " [ 2.26598    -2.9845414 ]\n",
      " [ 2.2319963  -3.047673  ]\n",
      " [ 2.3593533  -2.954049  ]\n",
      " [ 2.4932761  -3.1762009 ]\n",
      " [ 2.2669816  -3.028852  ]\n",
      " [ 2.1110432  -2.748727  ]\n",
      " [ 1.5248964  -2.0102024 ]\n",
      " [ 2.2687087  -3.0915077 ]\n",
      " [ 2.5269074  -3.1124387 ]\n",
      " [ 0.84441304 -1.1559284 ]\n",
      " [ 1.1890252  -1.5783148 ]\n",
      " [-1.6559842   2.1203108 ]\n",
      " [ 2.5359228  -3.217498  ]\n",
      " [-2.29062     2.6790845 ]\n",
      " [-1.8326496   2.1993756 ]\n",
      " [-1.5782092   2.1363506 ]\n",
      " [-2.188976    2.3919036 ]\n",
      " [ 0.02062938  0.03524572]\n",
      " [ 2.5926173  -3.3603172 ]\n",
      " [ 2.5058925  -3.2743094 ]\n",
      " [-1.9990327   2.4902446 ]\n",
      " [ 2.5010045  -3.2288659 ]\n",
      " [-0.60769063  0.8874525 ]\n",
      " [-0.28044772  0.52468795]\n",
      " [ 2.5375776  -3.2038496 ]\n",
      " [ 1.876892   -2.5513573 ]\n",
      " [-2.2255826   2.6332319 ]\n",
      " [ 2.425731   -3.2542405 ]\n",
      " [ 1.9032067  -2.649378  ]\n",
      " [ 2.4535732  -3.1523402 ]\n",
      " [-1.5607859   1.8411491 ]\n",
      " [ 2.5059848  -3.237136  ]\n",
      " [ 2.4949627  -3.3026521 ]\n",
      " [-2.472642    2.9304714 ]\n",
      " [ 1.6957792  -2.3165867 ]\n",
      " [-1.1127317   1.5469168 ]\n",
      " [ 2.5132706  -3.2175634 ]\n",
      " [-2.4713767   2.8747284 ]\n",
      " [ 2.400866   -3.057359  ]\n",
      " [-1.8272684   2.0098631 ]\n",
      " [-1.8342726   2.1687896 ]\n",
      " [ 2.485038   -3.2482407 ]\n",
      " [ 0.88975424 -1.2741687 ]\n",
      " [ 2.1170914  -2.7415946 ]\n",
      " [ 2.5201805  -3.26657   ]\n",
      " [ 2.5522594  -3.2887347 ]\n",
      " [ 2.4696364  -3.2194645 ]\n",
      " [ 2.5960429  -3.3390594 ]\n",
      " [ 2.4807494  -3.1024408 ]\n",
      " [-2.4299095   2.8220465 ]\n",
      " [ 2.5754623  -3.3219275 ]\n",
      " [ 2.5721774  -3.2836962 ]\n",
      " [ 2.3760445  -3.014388  ]\n",
      " [ 2.3825905  -3.0919902 ]\n",
      " [ 2.5924706  -3.3175464 ]\n",
      " [-2.464414    2.858958  ]\n",
      " [ 2.3900404  -3.057189  ]\n",
      " [ 2.5815458  -3.3193727 ]\n",
      " [ 2.5821679  -3.269683  ]\n",
      " [ 2.3789341  -3.121867  ]\n",
      " [-2.231487    2.6588485 ]\n",
      " [-1.940063    2.310572  ]\n",
      " [-2.3926876   2.7936215 ]\n",
      " [ 2.3433561  -3.1314077 ]\n",
      " [-2.3989685   2.7942    ]\n",
      " [ 2.5798037  -3.2857356 ]\n",
      " [ 2.3983893  -3.2088478 ]\n",
      " [ 2.35552    -3.181902  ]\n",
      " [ 2.2813492  -3.0362005 ]\n",
      " [ 0.04725365  0.02784331]\n",
      " [ 2.3534255  -3.2053277 ]\n",
      " [ 2.3950348  -3.0406554 ]\n",
      " [-2.4225562   2.787584  ]\n",
      " [ 0.3711536  -0.6088347 ]\n",
      " [ 2.5300803  -3.2962463 ]\n",
      " [ 2.5663264  -3.2258005 ]\n",
      " [ 2.4560566  -3.2844834 ]\n",
      " [-2.429236    2.8613536 ]\n",
      " [ 2.5231364  -3.1829755 ]\n",
      " [-2.2065241   2.639407  ]\n",
      " [ 2.4688563  -3.1600206 ]\n",
      " [-0.9784142   1.1579458 ]\n",
      " [ 2.561006   -3.2735524 ]\n",
      " [-0.23105185  0.27844214]\n",
      " [ 2.4578938  -3.111455  ]\n",
      " [ 2.382482   -3.201315  ]\n",
      " [ 2.3897388  -3.0621958 ]\n",
      " [ 2.553552   -3.1712346 ]\n",
      " [ 2.447469   -3.1356108 ]\n",
      " [-2.3591917   2.7284849 ]\n",
      " [ 2.4857812  -3.234197  ]\n",
      " [ 2.3583193  -3.030867  ]\n",
      " [ 2.458984   -2.9995909 ]\n",
      " [-2.2882087   2.688365  ]\n",
      " [ 2.0504615  -2.6372645 ]\n",
      " [ 2.5031204  -3.2234259 ]\n",
      " [-2.2451766   2.6725924 ]\n",
      " [-2.3802152   2.7733083 ]\n",
      " [ 2.3949475  -3.0738206 ]\n",
      " [ 2.5283206  -3.1544542 ]\n",
      " [ 2.586201   -3.268382  ]\n",
      " [-2.2204795   2.5906146 ]\n",
      " [ 2.5565875  -3.2784479 ]] [1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.83636     3.3247542 ]\n",
      " [-2.1598759   2.3556461 ]\n",
      " [ 2.1138601  -2.6696517 ]\n",
      " [ 2.8243814  -3.7703583 ]\n",
      " [ 2.272965   -3.202106  ]\n",
      " [ 2.887612   -3.702949  ]\n",
      " [ 2.0069776  -2.8580718 ]\n",
      " [ 2.992893   -3.7730908 ]\n",
      " [-2.9262838   3.4135096 ]\n",
      " [ 2.8871074  -3.635265  ]\n",
      " [-2.768259    3.2271204 ]\n",
      " [-2.904539    3.3678262 ]\n",
      " [ 2.8573852  -3.6490169 ]\n",
      " [ 2.7936554  -3.6868663 ]\n",
      " [ 2.960144   -3.6898906 ]\n",
      " [ 2.9218311  -3.7078686 ]\n",
      " [-2.435907    2.812121  ]\n",
      " [-2.6366653   3.1372132 ]\n",
      " [-2.8599927   3.3304803 ]\n",
      " [-2.8692257   3.3573768 ]\n",
      " [ 2.8690453  -3.7299516 ]\n",
      " [ 2.8213553  -3.7405763 ]\n",
      " [-2.8264372   3.3178298 ]\n",
      " [ 2.8668072  -3.7159328 ]\n",
      " [-2.8133078   3.2799838 ]\n",
      " [ 2.9375453  -3.5974903 ]\n",
      " [-0.11200872  0.09063104]\n",
      " [ 2.829506   -3.5754523 ]\n",
      " [ 2.894609   -3.7285964 ]\n",
      " [-2.4799337   2.7775655 ]\n",
      " [ 3.0377786  -3.852217  ]\n",
      " [-2.3413484   2.5900156 ]\n",
      " [ 2.7973452  -3.5888283 ]\n",
      " [ 2.9028432  -3.7812536 ]\n",
      " [-2.2815635   2.6611018 ]\n",
      " [ 0.5705215  -0.77083844]\n",
      " [ 2.8981793  -3.6824086 ]\n",
      " [ 2.9731815  -3.7690632 ]\n",
      " [-2.5583978   2.8945773 ]\n",
      " [-2.9217308   3.4105465 ]\n",
      " [ 2.794251   -3.7574723 ]\n",
      " [-1.8618919   2.1304975 ]\n",
      " [ 2.7299333  -3.4667363 ]\n",
      " [ 2.831177   -3.616749  ]\n",
      " [ 2.8554618  -3.6867375 ]\n",
      " [ 2.8070066  -3.61834   ]\n",
      " [ 2.2157793  -3.1070042 ]\n",
      " [ 2.959116   -3.7771463 ]\n",
      " [-2.8431022   3.3121216 ]\n",
      " [-2.1946158   2.5812995 ]\n",
      " [ 2.8313065  -3.6042132 ]\n",
      " [ 2.770501   -3.6020021 ]\n",
      " [-2.5185924   2.7912555 ]\n",
      " [-2.6795008   3.0785408 ]\n",
      " [ 2.9743874  -3.8373137 ]\n",
      " [-2.8997245   3.3991609 ]\n",
      " [ 2.884612   -3.6370401 ]\n",
      " [-2.8568738   3.3334422 ]\n",
      " [ 2.3754754  -3.3009691 ]\n",
      " [ 2.891486   -3.7225206 ]\n",
      " [ 2.4538794  -3.0666971 ]\n",
      " [ 2.9013577  -3.6290388 ]\n",
      " [ 2.879708   -3.629885  ]\n",
      " [ 2.8060222  -3.585357  ]\n",
      " [-2.895461    3.3773236 ]\n",
      " [ 2.8162537  -3.4471765 ]\n",
      " [ 2.86141    -3.5993145 ]\n",
      " [ 2.7462559  -3.6322043 ]\n",
      " [ 2.9520252  -3.7714384 ]\n",
      " [ 0.13362667 -0.12306599]\n",
      " [ 2.9721918  -3.8022177 ]\n",
      " [ 2.9137864  -3.758332  ]\n",
      " [ 2.955278   -3.7124481 ]\n",
      " [ 2.9145403  -3.7336726 ]\n",
      " [-0.53497654  0.6169001 ]\n",
      " [ 2.8671682  -3.7218213 ]\n",
      " [ 2.7879994  -3.6570525 ]\n",
      " [-2.7371445   3.211242  ]\n",
      " [ 2.56104    -3.4202363 ]\n",
      " [-2.6921978   3.1025376 ]\n",
      " [-1.5778484   1.7797989 ]\n",
      " [ 2.652172   -3.3792856 ]\n",
      " [ 2.9110522  -3.6606836 ]\n",
      " [ 2.896871   -3.7517366 ]\n",
      " [ 3.0208786  -3.8417284 ]\n",
      " [-2.8341215   3.3274314 ]\n",
      " [ 2.6594517  -3.4072654 ]\n",
      " [-0.7864464   0.97086346]\n",
      " [ 2.1095839  -2.9445133 ]\n",
      " [ 2.8946497  -3.7237594 ]\n",
      " [-2.8458602   3.3499541 ]\n",
      " [ 2.269595   -3.2312803 ]\n",
      " [ 2.8559732  -3.6354375 ]\n",
      " [ 2.9793382  -3.7218273 ]\n",
      " [ 2.8301327  -3.715715  ]\n",
      " [ 2.751758   -3.6285725 ]\n",
      " [-2.724412    3.1524127 ]\n",
      " [ 2.9548166  -3.7546728 ]\n",
      " [-2.5256755   3.0249052 ]\n",
      " [ 2.622352   -3.4022086 ]\n",
      " [ 2.3367245  -3.2483923 ]\n",
      " [ 2.7001483  -3.3553915 ]\n",
      " [ 2.9164424  -3.7053447 ]\n",
      " [ 2.442733   -3.2936356 ]\n",
      " [ 2.5868464  -3.3099632 ]\n",
      " [-0.9308939   1.0813369 ]\n",
      " [ 2.481939   -3.3894882 ]\n",
      " [ 2.9153037  -3.6047711 ]\n",
      " [-2.4480114   2.7917023 ]\n",
      " [ 1.7079365  -2.217481  ]\n",
      " [-2.7191198   3.1114545 ]\n",
      " [ 2.9379327  -3.7171612 ]\n",
      " [-2.8610876   3.3586535 ]\n",
      " [-2.505218    2.9151576 ]\n",
      " [-2.834304    3.3085246 ]\n",
      " [-2.5638545   3.002912  ]\n",
      " [-2.1156616   2.482545  ]\n",
      " [ 2.945733   -3.8586032 ]\n",
      " [ 2.9030356  -3.7820172 ]\n",
      " [-2.9245768   3.3840184 ]\n",
      " [ 2.8657544  -3.696779  ]\n",
      " [-2.6258678   2.9943717 ]\n",
      " [-0.8826358   1.3025413 ]\n",
      " [ 2.960821   -3.748755  ]\n",
      " [ 2.519579   -3.4096518 ]\n",
      " [-2.8277626   3.3162837 ]\n",
      " [ 2.6757412  -3.616417  ]\n",
      " [ 1.8829919  -2.5246692 ]\n",
      " [ 2.8494027  -3.653319  ]\n",
      " [-2.4317136   2.6950936 ]\n",
      " [ 2.8771245  -3.738573  ]\n",
      " [ 2.88804    -3.8091989 ]\n",
      " [-2.9467957   3.444034  ]\n",
      " [-2.4657035   2.6144114 ]\n",
      " [-2.672174    3.0829253 ]\n",
      " [ 2.8970106  -3.7047873 ]\n",
      " [-2.9288425   3.4063423 ]\n",
      " [ 2.775785   -3.519571  ]\n",
      " [-2.5674596   2.8327127 ]\n",
      " [-2.6178923   3.0073369 ]\n",
      " [ 2.8603752  -3.7511525 ]\n",
      " [ 0.5445399  -0.7759838 ]\n",
      " [ 1.0806749  -1.5604609 ]\n",
      " [ 2.9088733  -3.7929468 ]\n",
      " [ 2.9605517  -3.821066  ]\n",
      " [ 2.8647447  -3.7463598 ]\n",
      " [ 2.9945705  -3.8482716 ]\n",
      " [ 2.8676693  -3.581956  ]\n",
      " [-2.865365    3.3424966 ]\n",
      " [ 2.9653773  -3.8408444 ]\n",
      " [ 2.9751291  -3.8016856 ]\n",
      " [ 2.5234766  -3.2584136 ]\n",
      " [ 2.653916   -3.4299111 ]\n",
      " [ 3.0249643  -3.888183  ]\n",
      " [-2.964762    3.417427  ]\n",
      " [ 2.7069762  -3.4128723 ]\n",
      " [ 2.9630272  -3.8040023 ]\n",
      " [ 2.9828744  -3.7895927 ]\n",
      " [ 2.8293889  -3.6750038 ]\n",
      " [-2.8761415   3.3477802 ]\n",
      " [-2.6675496   2.9886167 ]\n",
      " [-2.9228315   3.4112442 ]\n",
      " [ 2.6508296  -3.5087254 ]\n",
      " [-2.8627625   3.3537433 ]\n",
      " [ 2.976808   -3.8034902 ]\n",
      " [ 2.7360137  -3.6581361 ]\n",
      " [ 2.394471   -3.3396466 ]\n",
      " [ 2.4915984  -3.3370585 ]\n",
      " [-2.4789114   2.9570644 ]\n",
      " [ 2.5004787  -3.4690886 ]\n",
      " [ 2.6953394  -3.3979056 ]\n",
      " [-2.8289776   3.3172793 ]\n",
      " [-1.7785538   1.9698168 ]\n",
      " [ 2.9323778  -3.7993886 ]\n",
      " [ 2.9876025  -3.7816415 ]\n",
      " [ 2.8461165  -3.7804542 ]\n",
      " [-2.8841693   3.3767056 ]\n",
      " [ 2.8995783  -3.631011  ]\n",
      " [-2.8718548   3.340777  ]\n",
      " [ 2.8696523  -3.664615  ]\n",
      " [-2.4954164   2.776766  ]\n",
      " [ 2.961596   -3.8011482 ]\n",
      " [-1.4908606   1.7023597 ]\n",
      " [ 2.7921064  -3.5772233 ]\n",
      " [ 2.6614962  -3.5795438 ]\n",
      " [ 2.7511983  -3.573174  ]\n",
      " [ 2.950111   -3.6623976 ]\n",
      " [ 2.8483183  -3.605412  ]\n",
      " [-2.8461225   3.315779  ]\n",
      " [ 2.876479   -3.7007954 ]\n",
      " [ 2.7856405  -3.5502734 ]\n",
      " [ 2.880385   -3.5043936 ]\n",
      " [-2.6007822   3.1039026 ]\n",
      " [ 2.2876341  -2.8871882 ]\n",
      " [ 2.9184313  -3.7377043 ]\n",
      " [-2.9109972   3.3695862 ]\n",
      " [-2.894662    3.3463964 ]\n",
      " [ 2.6861792  -3.445554  ]\n",
      " [ 2.9206967  -3.6509454 ]\n",
      " [ 2.950733   -3.7264912 ]\n",
      " [-2.4176314   2.8773303 ]\n",
      " [ 2.9111133  -3.7224545 ]] [1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 202\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.9569836   3.433156  ]\n",
      " [ 1.4925021  -2.0173893 ]\n",
      " [ 2.5068002  -3.1438527 ]\n",
      " [ 2.939036   -3.868258  ]\n",
      " [ 2.5401945  -3.4563823 ]\n",
      " [ 2.9467452  -3.7504773 ]\n",
      " [ 2.426891   -3.3352234 ]\n",
      " [ 3.0553248  -3.8330207 ]\n",
      " [-3.0389926   3.5138304 ]\n",
      " [ 2.9618046  -3.6838892 ]\n",
      " [-2.849632    3.3102965 ]\n",
      " [-3.0182953   3.4662952 ]\n",
      " [ 2.9490201  -3.713091  ]\n",
      " [ 2.9183352  -3.7758462 ]\n",
      " [ 3.0065088  -3.7101817 ]\n",
      " [ 2.9689648  -3.742098  ]\n",
      " [-2.016796    2.388553  ]\n",
      " [-2.7267458   3.224454  ]\n",
      " [-2.9611707   3.4212492 ]\n",
      " [-2.9746606   3.4562738 ]\n",
      " [ 2.9370956  -3.7803295 ]\n",
      " [ 2.9348578  -3.837602  ]\n",
      " [-2.90588     3.3814971 ]\n",
      " [ 2.9152508  -3.7558181 ]\n",
      " [-2.850736    3.2931287 ]\n",
      " [ 2.9983246  -3.6613123 ]\n",
      " [ 1.2473527  -1.7026558 ]\n",
      " [ 2.9560819  -3.686551  ]\n",
      " [ 3.005128   -3.7977507 ]\n",
      " [-2.5124245   2.7501137 ]\n",
      " [ 3.1026142  -3.9030282 ]\n",
      " [-1.4140091   1.7320321 ]\n",
      " [ 2.950342   -3.6886754 ]\n",
      " [ 2.975609   -3.8495214 ]\n",
      " [-2.0997744   2.4873116 ]\n",
      " [ 1.4429731  -1.8844248 ]\n",
      " [ 2.9543517  -3.7113712 ]\n",
      " [ 3.0172668  -3.801365  ]\n",
      " [-2.4183357   2.7329857 ]\n",
      " [-3.0364263   3.5066168 ]\n",
      " [ 2.8606868  -3.8137932 ]\n",
      " [-0.5056081   0.76837796]\n",
      " [ 2.7793987  -3.479514  ]\n",
      " [ 2.8892384  -3.6831863 ]\n",
      " [ 2.9576726  -3.7633262 ]\n",
      " [ 2.8539162  -3.6374223 ]\n",
      " [ 2.388031   -3.2451231 ]\n",
      " [ 3.0217998  -3.817208  ]\n",
      " [-2.9459205   3.4042528 ]\n",
      " [-1.516661    1.9420493 ]\n",
      " [ 2.9139075  -3.6556835 ]\n",
      " [ 2.8789902  -3.6790838 ]\n",
      " [-2.5489073   2.7842653 ]\n",
      " [-2.7681913   3.1558473 ]\n",
      " [ 3.064625   -3.911321  ]\n",
      " [-3.0266254   3.508878  ]\n",
      " [ 2.9295256  -3.6753948 ]\n",
      " [-2.9634106   3.4274008 ]\n",
      " [ 2.649836   -3.5371494 ]\n",
      " [ 2.9410055  -3.7632303 ]\n",
      " [ 2.6993144  -3.3435512 ]\n",
      " [ 2.9604728  -3.6882474 ]\n",
      " [ 2.9269023  -3.682273  ]\n",
      " [ 2.9074128  -3.6502547 ]\n",
      " [-3.0128665   3.4810174 ]\n",
      " [ 2.8902514  -3.5249584 ]\n",
      " [ 2.9170299  -3.6263072 ]\n",
      " [ 2.877688   -3.7034492 ]\n",
      " [ 3.0189078  -3.8377862 ]\n",
      " [ 1.2068001  -1.6053835 ]\n",
      " [ 3.028798   -3.8340578 ]\n",
      " [ 2.9810205  -3.8242357 ]\n",
      " [ 3.0206327  -3.7892864 ]\n",
      " [ 2.99856    -3.7998002 ]\n",
      " [ 0.24487586 -0.43616313]\n",
      " [ 3.0107346  -3.854056  ]\n",
      " [ 2.960647   -3.785218  ]\n",
      " [-2.8022733   3.2537498 ]\n",
      " [ 2.8036277  -3.6185677 ]\n",
      " [-2.7837374   3.1853755 ]\n",
      " [ 0.15679984 -0.1037017 ]\n",
      " [ 2.7544613  -3.460852  ]\n",
      " [ 2.9459674  -3.668     ]\n",
      " [ 3.02179    -3.8427114 ]\n",
      " [ 3.0785227  -3.8957298 ]\n",
      " [-2.9364471   3.422335  ]\n",
      " [ 2.8034368  -3.5113196 ]\n",
      " [ 0.24777614 -0.46847227]\n",
      " [ 2.4698768  -3.341687  ]\n",
      " [ 2.937332   -3.7444723 ]\n",
      " [-2.9615974   3.45678   ]\n",
      " [ 2.5510046  -3.4851823 ]\n",
      " [ 2.9026284  -3.6556528 ]\n",
      " [ 3.0194075  -3.7305372 ]\n",
      " [ 2.9634311  -3.8187842 ]\n",
      " [ 2.8811212  -3.7207925 ]\n",
      " [-2.8140066   3.2232687 ]\n",
      " [ 3.0079162  -3.7936828 ]\n",
      " [-2.5957654   3.0888026 ]\n",
      " [ 2.6939614  -3.46291   ]\n",
      " [ 2.6437569  -3.524756  ]\n",
      " [ 2.8390605  -3.4845142 ]\n",
      " [ 2.9533079  -3.7360904 ]\n",
      " [ 2.5764074  -3.4147785 ]\n",
      " [ 2.7732437  -3.5254447 ]\n",
      " [ 1.3309482  -1.7310992 ]\n",
      " [ 2.7790494  -3.640521  ]\n",
      " [ 2.972971   -3.6651301 ]\n",
      " [-2.1716616   2.514677  ]\n",
      " [ 2.1082823  -2.705937  ]\n",
      " [-2.756762    3.1193244 ]\n",
      " [ 2.975544   -3.7412744 ]\n",
      " [-2.9572256   3.4470937 ]\n",
      " [-2.287874    2.6148481 ]\n",
      " [-2.9504385   3.4184153 ]\n",
      " [-2.6291041   3.0376077 ]\n",
      " [-1.9605012   2.356094  ]\n",
      " [ 3.0388832  -3.9303916 ]\n",
      " [ 2.949055   -3.8149512 ]\n",
      " [-3.0317082   3.4749641 ]\n",
      " [ 2.9719024  -3.7784243 ]\n",
      " [-2.6307027   2.951945  ]\n",
      " [-0.6065332   0.9344705 ]\n",
      " [ 3.0281508  -3.823161  ]\n",
      " [ 2.73018    -3.6218166 ]\n",
      " [-2.9345129   3.4119253 ]\n",
      " [ 2.8559618  -3.753291  ]\n",
      " [ 2.1187718  -2.8027606 ]\n",
      " [ 2.9123619  -3.7194626 ]\n",
      " [-1.7460908   1.9283748 ]\n",
      " [ 2.9594283  -3.785785  ]\n",
      " [ 2.949343   -3.8456347 ]\n",
      " [-3.0612183   3.5366135 ]\n",
      " [ 0.6887939  -0.8848706 ]\n",
      " [-2.7194424   3.1070178 ]\n",
      " [ 2.985474   -3.7613602 ]\n",
      " [-3.0444021   3.5061147 ]\n",
      " [ 2.8443782  -3.595425  ]\n",
      " [-2.590093    2.8112178 ]\n",
      " [-2.6041355   2.9513936 ]\n",
      " [ 2.930524   -3.7930558 ]\n",
      " [ 1.2713423  -1.6864406 ]\n",
      " [ 1.9537399  -2.5799727 ]\n",
      " [ 2.9794722  -3.8422189 ]\n",
      " [ 3.023734   -3.8803806 ]\n",
      " [ 2.932326   -3.781062  ]\n",
      " [ 3.0405161  -3.8913794 ]\n",
      " [ 2.9177682  -3.6310186 ]\n",
      " [-2.9859056   3.4512136 ]\n",
      " [ 3.0294793  -3.9028797 ]\n",
      " [ 3.026349   -3.836934  ]\n",
      " [ 2.708026   -3.4202206 ]\n",
      " [ 2.8695717  -3.65456   ]\n",
      " [ 3.0820894  -3.9398768 ]\n",
      " [-3.0821054   3.5124562 ]\n",
      " [ 2.8168485  -3.5294895 ]\n",
      " [ 3.0256088  -3.8553228 ]\n",
      " [ 3.0392492  -3.8451378 ]\n",
      " [ 2.8836937  -3.7052631 ]\n",
      " [-2.9803736   3.4401515 ]\n",
      " [-2.5042894   2.8471968 ]\n",
      " [-3.0323563   3.4990995 ]\n",
      " [ 2.852338   -3.7017205 ]\n",
      " [-2.9669485   3.4454794 ]\n",
      " [ 3.0515447  -3.8565037 ]\n",
      " [ 2.8973758  -3.7743342 ]\n",
      " [ 2.6838696  -3.599575  ]\n",
      " [ 2.6952434  -3.5299468 ]\n",
      " [-2.5111382   2.7876933 ]\n",
      " [ 2.723055   -3.6352348 ]\n",
      " [ 2.8257725  -3.524379  ]\n",
      " [-2.935587    3.415842  ]\n",
      " [-0.33738574  0.43743733]\n",
      " [ 2.9871297  -3.8394287 ]\n",
      " [ 3.0531588  -3.8540387 ]\n",
      " [ 2.9000185  -3.8021715 ]\n",
      " [-3.0039132   3.481213  ]\n",
      " [ 2.932995   -3.6509342 ]\n",
      " [-2.962644    3.410216  ]\n",
      " [ 2.9123058  -3.7018554 ]\n",
      " [-2.2574105   2.4647696 ]\n",
      " [ 3.0243042  -3.8616905 ]\n",
      " [ 0.92194694 -1.3850368 ]\n",
      " [ 2.9174469  -3.6692467 ]\n",
      " [ 2.8400228  -3.7137046 ]\n",
      " [ 2.8764584  -3.674439  ]\n",
      " [ 2.997626   -3.7040453 ]\n",
      " [ 2.88231    -3.629139  ]\n",
      " [-2.9557307   3.415074  ]\n",
      " [ 2.9309185  -3.7260442 ]\n",
      " [ 2.9388351  -3.7099295 ]\n",
      " [ 2.9326859  -3.5582695 ]\n",
      " [-2.667302    3.1641958 ]\n",
      " [ 2.6212873  -3.3700144 ]\n",
      " [ 2.985616   -3.7829196 ]\n",
      " [-3.0189226   3.464644  ]\n",
      " [-3.0085971   3.4403248 ]\n",
      " [ 2.8049862  -3.5404015 ]\n",
      " [ 2.9685817  -3.6848407 ]\n",
      " [ 3.0064225  -3.765309  ]\n",
      " [-2.4702694   2.865927  ]\n",
      " [ 3.0121748  -3.7855384 ]] [1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.16223356628417968, metrics={'train_runtime': 176.8386, 'train_samples_per_second': 22.789, 'train_steps_per_second': 1.414, 'total_flos': 1058758886768640.0, 'train_loss': 0.16223356628417968, 'epoch': 4.99})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7324d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_model\n",
      "Configuration saved in test_model\\config.json\n",
      "Model weights saved in test_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39f7c583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9967137575149536},\n",
       " {'label': 'LABEL_1', 'score': 0.999906063079834},\n",
       " {'label': 'LABEL_1', 'score': 0.9998805522918701},\n",
       " {'label': 'LABEL_0', 'score': 0.986866295337677}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\"./test_model\")\n",
    "\n",
    "pipe = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=0)\n",
    "pipe([\"I put the chicken in the oven for longer.\", \"I substituted the pears for apples.\", \"I added extra paprika.\", \"Eggs should be added.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5665c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
